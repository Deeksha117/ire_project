[14] and [12]) which has already found practical applications like the clustering of search results (see e.g.
Like the work presented in this paper, Li and Yamanishi ([10, 9]) try to ﬁnd characterizations of topics directly by clustering keywords using a statistical similarity measure.
Both our and their work are conceptually related to latent semantic analysis (LSA) [3, 7] and even more so to probabilistic latent semantic analysis (PLSA) [5, 6] and related work by [15].
Note that the probability measure ¯pz is very similar to the setup in [10, section 3].
The Jensen-Shannon divergence or information radius [11, 4] between two distributions p and q is deﬁned as 1 1 2 D(p||m) + 2 D(q ||m) JSD(p||q) =
Since the square root of the Jensen Shannon divergence is a proper metric [4], we have two distances
We have used the induced bisecting k-means clustering algorithm as described by [1], which is based on the standard bisecting k-means algorithm, see e.g.
[14].
First results suggested that this approach performed not as well as the kmeans algorithm, in line with similar ﬁndings by [14] and [12].
Before extracting keywords we do some preprocessing using the GAT E–framework [2].
Lemmatization and tagging is done using the Treetagger [13].
Following [8], we now compare with the set of clusters C of keywords found using the algorithm in section 3.4, different distance measures and different diameters.
